{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('./Dataset/train.csv')\n",
    "test = pd.read_csv('./Dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's see infos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to know how many people survived in each class. We can use the groupby method to quickly do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass  Survived\n",
       "1       1           136\n",
       "        0            80\n",
       "2       0            97\n",
       "        1            87\n",
       "3       0           372\n",
       "        1           119\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pclass = train.groupby('Pclass').Survived.value_counts() \n",
    "pclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we can see , the statistics show that the survival rate of the passengers in the first class is higher than the second and third class. we can exploit this info "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some additional features from the existing ones ( feature engineering ) . first let's add , family size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering (train, test):\n",
    "    train['Family_Size']=train['SibSp']+train['Parch']\n",
    "    test['Family_Size']=test['SibSp']+test['Parch']\n",
    "    train[\"Level\"]=(train[\"Pclass\"])*train[\"Fare\"]*train[\"Age\"]\n",
    "    test[\"Level\"]=(test[\"Pclass\"])*test[\"Fare\"]*test[\"Age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.copy()\n",
    "test_df = test.copy()\n",
    "feature_engineering(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = train_df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived       1.000000\n",
       "Fare           0.257307\n",
       "Level          0.173592\n",
       "Parch          0.081629\n",
       "Family_Size    0.016639\n",
       "PassengerId   -0.005007\n",
       "SibSp         -0.035322\n",
       "Age           -0.077221\n",
       "Pclass        -0.338481\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix[\"Survived\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see , it seems that the Fare and Pclass are the most correlated attributes with the Survived attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's prepare our train set now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Sampling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use Startified sampling from scikit learn , basically strata means spliting your dataset into many "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X= train_df.drop(['Survived'], axis=1)\n",
    "y= train_df['Survived']\n",
    "train_X, val_X ,train_y, val_y= train_test_split(X,y, test_size=0.2, stratify=train_df[\"Survived\"], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's create a pipline that prepares the data for training. but before let devise our dataset into numerical and categorical sub datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features=[\"Age\",'Fare',\"Pclass\",\"Family_Size\"]\n",
    "cat_features=['Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "num_pipeline = Pipeline([\n",
    " ('imputer', SimpleImputer(strategy=\"median\")),\n",
    " ('std_scaler', StandardScaler()),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "full_pipeline = ColumnTransformer([(\"num_pipeline\", num_pipeline, num_features),(\"cat\", OneHotEncoder(), cat_features)])\n",
    "train_prepared = full_pipeline.fit_transform(train_X)\n",
    "val_prepared = full_pipeline.transform(val_X)\n",
    "test_prepared = full_pipeline.transform(test_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are many binary classification estimators , we want to choose the best one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifiers = [LogisticRegression(),RandomForestClassifier(),KNeighborsClassifier()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's evaluate the models without performing any hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() roc_auc 0.7986824769433466\n",
      "LogisticRegression() accuracy 0.8156424581005587\n",
      "LogisticRegression() precision 0.78125\n",
      "LogisticRegression() recall 0.7246376811594203\n",
      "RandomForestClassifier() roc_auc 0.7868906455862978\n",
      "RandomForestClassifier() accuracy 0.8044692737430168\n",
      "RandomForestClassifier() precision 0.765625\n",
      "RandomForestClassifier() recall 0.7101449275362319\n",
      "KNeighborsClassifier() roc_auc 0.8013833992094862\n",
      "KNeighborsClassifier() accuracy 0.8156424581005587\n",
      "KNeighborsClassifier() precision 0.7727272727272727\n",
      "KNeighborsClassifier() recall 0.7391304347826086\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,recall_score,precision_score\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(train_prepared, train_y)\n",
    "    pred= classifier.predict(val_prepared)\n",
    "    print(classifier,\"roc_auc\",roc_auc_score(val_y, pred, average='weighted'))\n",
    "    print(classifier,\"accuracy\",accuracy_score(val_y, pred))\n",
    "    print(classifier,\"precision\",precision_score(val_y, pred))\n",
    "    print(classifier,\"recall\",recall_score(val_y, pred))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous results , we can say that the logistic regression is the best model to use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first let's prepare the dataset for this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_X = full_pipeline.fit_transform(X)\n",
    "final_train_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2000 candidates, totalling 20000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "10230 fits failed out of a total of 20000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "690 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 233, in fit\n",
      "    return self._fit(X, y)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 644, in _fit\n",
      "    self._tree = BallTree(\n",
      "                 ^^^^^^^^^\n",
      "  File \"sklearn\\neighbors\\_binary_tree.pxi\", line 837, in sklearn.neighbors._ball_tree.BinaryTree.__init__\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 211, in sklearn.metrics._dist_metrics.DistanceMetric.get_metric\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 437, in sklearn.metrics._dist_metrics.DistanceMetric64.get_metric\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 1098, in sklearn.metrics._dist_metrics.SEuclideanDistance64.__init__\n",
      "TypeError: __init__() takes exactly 1 positional argument (0 given)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2710 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 233, in fit\n",
      "    return self._fit(X, y)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 661, in _fit\n",
      "    self._tree = KDTree(\n",
      "                 ^^^^^^^\n",
      "  File \"sklearn\\neighbors\\_binary_tree.pxi\", line 837, in sklearn.neighbors._kd_tree.BinaryTree.__init__\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 211, in sklearn.metrics._dist_metrics.DistanceMetric.get_metric\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 437, in sklearn.metrics._dist_metrics.DistanceMetric64.get_metric\n",
      "TypeError: __init__() got an unexpected keyword argument 'V'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 233, in fit\n",
      "    return self._fit(X, y)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 644, in _fit\n",
      "    self._tree = BallTree(\n",
      "                 ^^^^^^^^^\n",
      "  File \"sklearn\\neighbors\\_binary_tree.pxi\", line 837, in sklearn.neighbors._ball_tree.BinaryTree.__init__\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 211, in sklearn.metrics._dist_metrics.DistanceMetric.get_metric\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 437, in sklearn.metrics._dist_metrics.DistanceMetric64.get_metric\n",
      "TypeError: __init__() got an unexpected keyword argument 'V'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 233, in fit\n",
      "    return self._fit(X, y)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 644, in _fit\n",
      "    self._tree = BallTree(\n",
      "                 ^^^^^^^^^\n",
      "  File \"sklearn\\neighbors\\_binary_tree.pxi\", line 837, in sklearn.neighbors._ball_tree.BinaryTree.__init__\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 211, in sklearn.metrics._dist_metrics.DistanceMetric.get_metric\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 437, in sklearn.metrics._dist_metrics.DistanceMetric64.get_metric\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 1601, in sklearn.metrics._dist_metrics.MahalanobisDistance64.__init__\n",
      "ValueError: Must provide either V or VI for Mahalanobis distance\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "650 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 233, in fit\n",
      "    return self._fit(X, y)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 500, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 434, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'mahalanobis' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['kd_tree']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "303 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'metric' parameter of KNeighborsClassifier must be a str among {'pyfunc', 'rogerstanimoto', 'yule', 'cityblock', 'canberra', 'correlation', 'chebyshev', 'sokalsneath', 'russellrao', 'sokalmichener', 'hamming', 'nan_euclidean', 'l1', 'p', 'l2', 'sqeuclidean', 'dice', 'minkowski', 'infinity', 'jaccard', 'precomputed', 'haversine', 'mahalanobis', 'euclidean', 'manhattan', 'braycurtis', 'seuclidean', 'cosine'} or a callable. Got 'wminkowski' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'metric' parameter of KNeighborsClassifier must be a str among {'braycurtis', 'p', 'canberra', 'pyfunc', 'haversine', 'hamming', 'dice', 'correlation', 'seuclidean', 'sokalmichener', 'l2', 'rogerstanimoto', 'cityblock', 'mahalanobis', 'infinity', 'sqeuclidean', 'chebyshev', 'russellrao', 'jaccard', 'minkowski', 'euclidean', 'precomputed', 'yule', 'l1', 'sokalsneath', 'cosine', 'manhattan', 'nan_euclidean'} or a callable. Got 'wminkowski' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "326 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'metric' parameter of KNeighborsClassifier must be a str among {'dice', 'sokalmichener', 'mahalanobis', 'correlation', 'nan_euclidean', 'l2', 'manhattan', 'hamming', 'l1', 'infinity', 'sokalsneath', 'russellrao', 'jaccard', 'haversine', 'euclidean', 'yule', 'seuclidean', 'cosine', 'cityblock', 'braycurtis', 'p', 'minkowski', 'chebyshev', 'sqeuclidean', 'canberra', 'precomputed', 'rogerstanimoto', 'pyfunc'} or a callable. Got 'wminkowski' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "272 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'metric' parameter of KNeighborsClassifier must be a str among {'infinity', 'russellrao', 'cityblock', 'mahalanobis', 'p', 'seuclidean', 'sokalsneath', 'cosine', 'minkowski', 'braycurtis', 'rogerstanimoto', 'canberra', 'sqeuclidean', 'precomputed', 'yule', 'euclidean', 'manhattan', 'dice', 'haversine', 'l2', 'correlation', 'hamming', 'jaccard', 'l1', 'pyfunc', 'chebyshev', 'nan_euclidean', 'sokalmichener'} or a callable. Got 'wminkowski' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "580 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 233, in fit\n",
      "    return self._fit(X, y)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 500, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 434, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'seuclidean' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['kd_tree']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "442 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'metric' parameter of KNeighborsClassifier must be a str among {'haversine', 'braycurtis', 'jaccard', 'p', 'minkowski', 'correlation', 'yule', 'sokalsneath', 'l2', 'seuclidean', 'hamming', 'manhattan', 'sokalmichener', 'infinity', 'rogerstanimoto', 'cosine', 'nan_euclidean', 'cityblock', 'dice', 'chebyshev', 'sqeuclidean', 'l1', 'russellrao', 'pyfunc', 'precomputed', 'canberra', 'mahalanobis', 'euclidean'} or a callable. Got 'wminkowski' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "680 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 233, in fit\n",
      "    return self._fit(X, y)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 644, in _fit\n",
      "    self._tree = BallTree(\n",
      "                 ^^^^^^^^^\n",
      "  File \"sklearn\\neighbors\\_binary_tree.pxi\", line 837, in sklearn.neighbors._ball_tree.BinaryTree.__init__\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 211, in sklearn.metrics._dist_metrics.DistanceMetric.get_metric\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 437, in sklearn.metrics._dist_metrics.DistanceMetric64.get_metric\n",
      "  File \"sklearn\\metrics\\_dist_metrics.pyx\", line 1099, in sklearn.metrics._dist_metrics.SEuclideanDistance64.__init__\n",
      "ValueError: Buffer has wrong number of dimensions (expected 1, got 2)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "345 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'metric' parameter of KNeighborsClassifier must be a str among {'nan_euclidean', 'canberra', 'euclidean', 'minkowski', 'sokalsneath', 'chebyshev', 'sokalmichener', 'sqeuclidean', 'cityblock', 'seuclidean', 'l2', 'jaccard', 'cosine', 'yule', 'correlation', 'mahalanobis', 'dice', 'precomputed', 'l1', 'braycurtis', 'hamming', 'infinity', 'manhattan', 'p', 'rogerstanimoto', 'pyfunc', 'russellrao', 'haversine'} or a callable. Got 'wminkowski' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "382 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'metric' parameter of KNeighborsClassifier must be a str among {'pyfunc', 'yule', 'l1', 'correlation', 'sokalmichener', 'chebyshev', 'infinity', 'manhattan', 'p', 'haversine', 'hamming', 'dice', 'sokalsneath', 'cosine', 'sqeuclidean', 'cityblock', 'rogerstanimoto', 'minkowski', 'braycurtis', 'canberra', 'euclidean', 'seuclidean', 'l2', 'jaccard', 'precomputed', 'nan_euclidean', 'russellrao', 'mahalanobis'} or a callable. Got 'wminkowski' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "330 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'metric' parameter of KNeighborsClassifier must be a str among {'canberra', 'p', 'sokalmichener', 'l2', 'precomputed', 'mahalanobis', 'nan_euclidean', 'cosine', 'l1', 'minkowski', 'chebyshev', 'infinity', 'rogerstanimoto', 'seuclidean', 'yule', 'haversine', 'euclidean', 'sokalsneath', 'cityblock', 'jaccard', 'hamming', 'sqeuclidean', 'pyfunc', 'manhattan', 'correlation', 'russellrao', 'braycurtis', 'dice'} or a callable. Got 'wminkowski' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "e:\\programming\\AI\\Titanic_Disaster_Detection\\Project1\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.81146067        nan        nan ...        nan        nan 0.81602996]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10, estimator=KNeighborsClassifier(), n_iter=2000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;,\n",
       "                                                      &#x27;kd_tree&#x27;, &#x27;brute&#x27;],\n",
       "                                        &#x27;leaf_size&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...],\n",
       "                                        &#x27;metric&#x27;: [&#x27;minkowski&#x27;, &#x27;euclidean&#x27;,\n",
       "                                                   &#x27;manhattan&#x27;, &#x27;chebyshev&#x27;,\n",
       "                                                   &#x27;wminkowski&#x27;, &#x27;seuclidean&#x27;,\n",
       "                                                   &#x27;mahalanobis&#x27;],...\n",
       "       [0.09514804, 0.9356509 , 0.81646114, 0.55492615, 0.84472242,\n",
       "        0.35646421],\n",
       "       [0.75764347, 0.66852076, 0.79342086, 0.82106624, 0.4416795 ,\n",
       "        0.92183626],\n",
       "       [0.16583507, 0.33361598, 0.94217856, 0.81807293, 0.77690188,\n",
       "        0.65524291]])}],\n",
       "                                        &#x27;n_jobs&#x27;: [-1],\n",
       "                                        &#x27;n_neighbors&#x27;: [1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                                                        9, 10, 11, 12, 13, 14,\n",
       "                                                        15, 16, 17, 18, 19, 20,\n",
       "                                                        21, 22, 23, 24, 25, 26,\n",
       "                                                        27, 28, 29, 30],\n",
       "                                        &#x27;p&#x27;: [1, 2],\n",
       "                                        &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10, estimator=KNeighborsClassifier(), n_iter=2000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;,\n",
       "                                                      &#x27;kd_tree&#x27;, &#x27;brute&#x27;],\n",
       "                                        &#x27;leaf_size&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...],\n",
       "                                        &#x27;metric&#x27;: [&#x27;minkowski&#x27;, &#x27;euclidean&#x27;,\n",
       "                                                   &#x27;manhattan&#x27;, &#x27;chebyshev&#x27;,\n",
       "                                                   &#x27;wminkowski&#x27;, &#x27;seuclidean&#x27;,\n",
       "                                                   &#x27;mahalanobis&#x27;],...\n",
       "       [0.09514804, 0.9356509 , 0.81646114, 0.55492615, 0.84472242,\n",
       "        0.35646421],\n",
       "       [0.75764347, 0.66852076, 0.79342086, 0.82106624, 0.4416795 ,\n",
       "        0.92183626],\n",
       "       [0.16583507, 0.33361598, 0.94217856, 0.81807293, 0.77690188,\n",
       "        0.65524291]])}],\n",
       "                                        &#x27;n_jobs&#x27;: [-1],\n",
       "                                        &#x27;n_neighbors&#x27;: [1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                                                        9, 10, 11, 12, 13, 14,\n",
       "                                                        15, 16, 17, 18, 19, 20,\n",
       "                                                        21, 22, 23, 24, 25, 26,\n",
       "                                                        27, 28, 29, 30],\n",
       "                                        &#x27;p&#x27;: [1, 2],\n",
       "                                        &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=KNeighborsClassifier(), n_iter=2000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'algorithm': ['auto', 'ball_tree',\n",
       "                                                      'kd_tree', 'brute'],\n",
       "                                        'leaf_size': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...],\n",
       "                                        'metric': ['minkowski', 'euclidean',\n",
       "                                                   'manhattan', 'chebyshev',\n",
       "                                                   'wminkowski', 'seuclidean',\n",
       "                                                   'mahalanobis'],...\n",
       "       [0.09514804, 0.9356509 , 0.81646114, 0.55492615, 0.84472242,\n",
       "        0.35646421],\n",
       "       [0.75764347, 0.66852076, 0.79342086, 0.82106624, 0.4416795 ,\n",
       "        0.92183626],\n",
       "       [0.16583507, 0.33361598, 0.94217856, 0.81807293, 0.77690188,\n",
       "        0.65524291]])}],\n",
       "                                        'n_jobs': [-1],\n",
       "                                        'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                                                        9, 10, 11, 12, 13, 14,\n",
       "                                                        15, 16, 17, 18, 19, 20,\n",
       "                                                        21, 22, 23, 24, 25, 26,\n",
       "                                                        27, 28, 29, 30],\n",
       "                                        'p': [1, 2],\n",
       "                                        'weights': ['uniform', 'distance']},\n",
       "                   scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "logistic = KNeighborsClassifier()\n",
    "param_dist = {\n",
    "    'n_neighbors': list(range(1, 31)),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size': list(range(1,51)),\n",
    "    'p': [1, 2],\n",
    "    'metric': ['minkowski', 'euclidean', 'manhattan', 'chebyshev', 'wminkowski', 'seuclidean', 'mahalanobis'],\n",
    "    'metric_params': [None, {'V': np.random.random((final_train_X.shape[1], final_train_X.shape[1])) for _ in range(10)}],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "rand_search = RandomizedSearchCV(estimator=logistic, param_distributions=param_dist,n_iter=2000, cv= 10 ,scoring=\"accuracy\", verbose=3, n_jobs=-1)\n",
    "rand_search.fit(final_train_X, final_train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights': 'uniform',\n",
       " 'p': 2,\n",
       " 'n_neighbors': 6,\n",
       " 'n_jobs': -1,\n",
       " 'metric_params': None,\n",
       " 'metric': 'manhattan',\n",
       " 'leaf_size': 5,\n",
       " 'algorithm': 'ball_tree'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8317103620474405"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the stratified kfold cross validation method to evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "def stratified_cross_val(model, X, y, n_splits=20):\n",
    "    accuracy=[]\n",
    "    skf= StratifiedKFold(n_splits=n_splits)\n",
    "    final_train_X = pd.DataFrame(X)\n",
    "    skf.get_n_splits(final_train_X, y)\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        train_X, val_X = X[train_index], X[test_index]\n",
    "        train_y, val_y = y[train_index], y[test_index]\n",
    "        model.fit(train_X, train_y)\n",
    "        pred= model.predict(val_X)\n",
    "        score = accuracy_score(val_y, pred)\n",
    "        accuracy.append(score)\n",
    "    return mean(accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from what we can see , the logistic regression classifier is the best performs better than the other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8362121212121213\n"
     ]
    }
   ],
   "source": [
    "print(stratified_cross_val(model, final_train_X, final_train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(final_train_X, final_train_y)\n",
    "predictions = model.predict(test_prepared)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's now save the submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
